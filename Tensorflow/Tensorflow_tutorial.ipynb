{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLyLTy97CiznUYfUTcKUwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roselidev/Studylog/blob/master/Tensorflow/Tensorflow_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ftJPOSV8fk4"
      },
      "source": [
        "# 텐서플로우 튜토리얼 Line By Line 톺아보기\r\n",
        "\r\n",
        "참고자료 : https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/get_started/ \\\r\n",
        "\r\n",
        "텐서플로우 v1.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv86vC_zyNkz"
      },
      "source": [
        "시작 전 TF 버전 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kf2GyxLP6qV-",
        "outputId": "413592e2-cdcb-4a2b-e8fd-1fef93a86585"
      },
      "source": [
        "!pip uninstall tensorflow\r\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.3MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8a1028b0d331eb14e85736045c35c9174f55801a11792482f4aa791331c9ad3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0eKm5KnysVR"
      },
      "source": [
        "## [시작하기](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/get_started/) 톺아보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGkG34zJ8Rcq"
      },
      "source": [
        "### 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS2aUnRkyJJM",
        "outputId": "60099018-68b2-451b-8935-e17afa0a968b"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\r\n",
        "x_data = np.random.rand(100).astype(np.float32)\r\n",
        "y_data = x_data * 0.1 + 0.3\r\n",
        "\r\n",
        "# Try to find values for W and b that compute y_data = W * x_data + b\r\n",
        "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\r\n",
        "# figure that out for us.)\r\n",
        "W = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\r\n",
        "b = tf.Variable(tf.zeros([1]))\r\n",
        "y = W * x_data + b\r\n",
        "\r\n",
        "# Minimize the mean squared errors.\r\n",
        "loss = tf.reduce_mean(tf.square(y - y_data))\r\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.5)\r\n",
        "train = optimizer.minimize(loss)\r\n",
        "\r\n",
        "# Before starting, initialize the variables.  We will 'run' this first.\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "\r\n",
        "# Launch the graph.\r\n",
        "sess = tf.Session()\r\n",
        "sess.run(init)\r\n",
        "\r\n",
        "# Fit the line.\r\n",
        "for step in range(201):\r\n",
        "    sess.run(train)\r\n",
        "    if step % 20 == 0:\r\n",
        "        print(step, sess.run(W), sess.run(b))\r\n",
        "\r\n",
        "# Learns best fit is W: [0.1], b: [0.3]\r\n",
        "\r\n",
        "# Close the Session when we're done.\r\n",
        "sess.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [0.09574598] [0.40571404]\n",
            "20 [0.0896285] [0.3053846]\n",
            "40 [0.09769081] [0.3011989]\n",
            "60 [0.09948587] [0.30026692]\n",
            "80 [0.09988553] [0.30005944]\n",
            "100 [0.09997451] [0.30001324]\n",
            "120 [0.09999432] [0.30000296]\n",
            "140 [0.09999876] [0.30000067]\n",
            "160 [0.09999973] [0.30000016]\n",
            "180 [0.0999999] [0.30000007]\n",
            "200 [0.0999999] [0.30000007]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oo5Icv8yxdW"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8KDT-hiyn18"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnLQCgazzD3v"
      },
      "source": [
        "### y = x * 0.1 + 0.3인 100개의 데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUaSTOddzWiE"
      },
      "source": [
        "x_data = np.random.rand(100).astype(np.float32)\r\n",
        "y_data = x_data * 0.1 + 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmIX-iFAznUZ"
      },
      "source": [
        "### Y = wX+b 인 식에서 w와 b를 찾도록 세팅하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzFQBUjz0QZ"
      },
      "source": [
        "W = tf.Variable(tf.random.uniform([1], -1.0, 1.0))\r\n",
        "b = tf.Variable(tf.zeros([1]))\r\n",
        "y = W * x_data + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeybvZtH0pt0"
      },
      "source": [
        "#### random_uniform 함수 \r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "tf.random.uniform(\r\n",
        "    shape, \r\n",
        "    minval=0, \r\n",
        "    maxval=None, \r\n",
        "    dtype=tf.dtypes.float32, \r\n",
        "    seed=None, \r\n",
        "    name=None\r\n",
        ")\r\n",
        "```\r\n",
        "\r\n",
        "균등분포로 선정된 랜덤값이 채워진 텐서 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOhc5wFc1AiG"
      },
      "source": [
        "#### zeros 함수\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "tf.zeros(\r\n",
        "    shape,\r\n",
        "    dtype=tf.float32,\r\n",
        "    name=None\r\n",
        ")\r\n",
        "```\r\n",
        "\r\n",
        "shape 만큼 0으로 채워진 텐서 반환\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2B1636N1dXQ"
      },
      "source": [
        "### loss func, optimizer, train func 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLhqqCed1oZd"
      },
      "source": [
        "loss = tf.reduce_mean(tf.square(y - y_data))\r\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.5)\r\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ethZEjNf2Gre"
      },
      "source": [
        "#### reduce_mean 함수\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "tf.reduce_mean(\r\n",
        "    input_tensor,\r\n",
        "    axis=None,\r\n",
        "    keepdims=None,\r\n",
        "    name=None,\r\n",
        "    reduction_indices=None,\r\n",
        "    keep_dims=None\r\n",
        ")\r\n",
        "```\r\n",
        "\r\n",
        "입력하는 축에 따라 평균값 계산. 결과적으로 입력한 축은 제거된다. \\\r\n",
        "e.g) axis == 0 : 한 행이 되도록 합친다 / axis == 1 : 한 열이 되도록 합친다\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHTrKlvF3vjW"
      },
      "source": [
        "#### train.GradientDescentOptimizer 함수\r\n",
        "\r\n",
        "```\r\n",
        "__init__(\r\n",
        "    learning_rate,\r\n",
        "    use_locking=False,\r\n",
        "    name='GradientDescent'\r\n",
        ")\r\n",
        "```\r\n",
        "새로운 optimizer instance를 생성한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA5Z8on25wCT"
      },
      "source": [
        "### 훈련 시작 전 변수 초기화 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zqRW54851yS"
      },
      "source": [
        "init = tf.global_variables_initializer() # W, b 초기화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkf6IA3y5_ec"
      },
      "source": [
        "### 세션 시작 및 변수 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5-D_Nmb6BnF"
      },
      "source": [
        "sess = tf.Session()\r\n",
        "sess.run(init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a38h8a1U6KNB"
      },
      "source": [
        "### 세션 과정 선언\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsiWnfIQ6PFX"
      },
      "source": [
        "for step in range(201):\r\n",
        "    sess.run(train)\r\n",
        "    if step % 20 == 0:\r\n",
        "        print(step, sess.run(W), sess.run(b)) # logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZctbKJE6cCd"
      },
      "source": [
        "### 세션 종료"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK4EMWpZ6eIv"
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnhDVGLU8v91"
      },
      "source": [
        "## [MNIST tutorial](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/mnist/pros/) 톺아보기\r\n",
        "\r\n",
        "이미 line by line으로 잘 설명되어 있어 따로 설명은 생략."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBbRQL02aTCf"
      },
      "source": [
        "### 전체코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "jpo9Uq7yaV6M",
        "outputId": "d19f61ab-6194-40e0-ab10-009a34d8d58a"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "\r\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\r\n",
        "\r\n",
        "sess = tf.InteractiveSession() # 선언부와 실행부 통합\r\n",
        "\r\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784]) # 784 = 28*28 (image shape flattened)\r\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10]) # 10개의 결과 클래스\r\n",
        "\r\n",
        "# 변수 선언\r\n",
        "W = tf.Variable(tf.zeros([784,10]))\r\n",
        "b = tf.Variable(tf.zeros([10]))\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "# 모델 선언\r\n",
        "y = tf.nn.softmax(tf.matmul(x,W) + b)\r\n",
        "\r\n",
        "# 오차함수 선언\r\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\r\n",
        "\r\n",
        "# 최적화함수 선언\r\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\r\n",
        "\r\n",
        "# 훈련 과정 선언\r\n",
        "for i in range(1000):\r\n",
        "  batch = mnist.train.next_batch(50)\r\n",
        "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\r\n",
        "\r\n",
        "# 모델 평가\r\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\r\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n",
        "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\r\n",
        "\r\n",
        "\r\n",
        "# 성능개선을 위한 새로운 모델\r\n",
        "# CNN\r\n",
        "\r\n",
        "def weight_variable(shape):\r\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1) # 잘린 정규 분포에서 랜덤 텐서 1개 반환\r\n",
        "  return tf.Variable(initial)\r\n",
        "\r\n",
        "def bias_variable(shape):\r\n",
        "  initial = tf.constant(0.1, shape=shape)\r\n",
        "  return tf.Variable(initial)\r\n",
        "\r\n",
        "def conv2d(x, W):\r\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n",
        "\r\n",
        "def max_pool_2x2(x):\r\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\r\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\r\n",
        "\r\n",
        "###### 여기서부터 shape 이해 안됨. . . .ㅜㅜ\r\n",
        "W_conv1 = weight_variable([5, 5, 1, 32])\r\n",
        "b_conv1 = bias_variable([32])\r\n",
        "x_image = tf.reshape(x, [-1,28,28,1])\r\n",
        "\r\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n",
        "h_pool1 = max_pool_2x2(h_conv1)\r\n",
        "W_conv2 = weight_variable([5, 5, 32, 64])\r\n",
        "b_conv2 = bias_variable([64])\r\n",
        "\r\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n",
        "h_pool2 = max_pool_2x2(h_conv2)\r\n",
        "W_fc1 = weight_variable([7 * 7 * 64, 1024])\r\n",
        "b_fc1 = bias_variable([1024])\r\n",
        "\r\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\r\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\r\n",
        "keep_prob = tf.placeholder(tf.float32)\r\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\r\n",
        "W_fc2 = weight_variable([1024, 10])\r\n",
        "b_fc2 = bias_variable([10])\r\n",
        "\r\n",
        "# 최종 모델 선언\r\n",
        "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\r\n",
        "# 오차함수\r\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\r\n",
        "# 최적화함수\r\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\r\n",
        "\r\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\r\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n",
        "\r\n",
        "sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "for i in range(20000):\r\n",
        "  batch = mnist.train.next_batch(50)\r\n",
        "  if i%100 == 0:\r\n",
        "    train_accuracy = accuracy.eval(feed_dict={\r\n",
        "        x:batch[0], y_: batch[1], keep_prob: 1.0})\r\n",
        "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\r\n",
        "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\r\n",
        "\r\n",
        "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\r\n",
        "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1bde213cc4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MNIST_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}